<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
</style>
<title>CS 184 Rasterizer</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">
</head>


<body>

<h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2020</h1>
<h1 align="middle">Project 1: Rasterizer</h1>
<h2 align="middle">Camran Kolahdouz-Isfahani, CS184</h2>

<br><br>

<div>

<h2 align="middle">Overview</h2>
<p>In this project I implement a simple rasterizer. The first part of the project was to simply draw triangles, from there I implemented supersampling and hierarchial transforms. Lastly, I implemented texture mapping with antialiasing methods. With completion, I built a functional vector graphics renderer for SVG files. I think this has been one of the most eye opening projects I have done at Cal. I play a lot of video games and learning how to render still images has convinced me of the challenge of rendering video games in real time. I think one of the most interesting lessons was how to move between many different spaces of representation and still preserve the world view of an image. There is so much work and genius at play to display that life-like image on our computer monitors.</p>



<h2 align="middle">Section I: Rasterization</h2>

<h3 align="middle">Part 1: Rasterizing single-color triangles</h3>
  <p>1. I create vectors based on the lines connecting the three points and I make sure they are going around the triangle in a counterclockwise direction. We can do the three line test which is an algorithm utilizing linear algebra properties with dot products relative to the point we are testing. If all return positive we know the point is contained in the triangle. We are basically testing if the point falls in the intersection of all the half plane faces.</p>
  <p> 2. My algorithm is no worse than one that checks each sample within the bounding box because it does exactly that. It is no worse if it does exactly the same thing. I go from the minimum x coordinate to the maximum x coordinate and same for the y coordinates.</p>
  <img src="./images/task1.png" align="middle" width="400px"/>
  <figcaption align="left">This is a screenshot captures the jaggies problem when we don't antialias.</figcaption>



<h3 align="middle">Part 2: Antialiasing triangles</h3>
  <p>1. After implementing the previous part, we see aliasing problems arise. Jaggies and moire on certain images. This is where we use antialiasing methods like supersampling. Instead of taking 1 sample from the middle of the pixel, we take a number of samples in each pixel equal to the sampling rate. We have a supersample buffer and a regular framebuffer. We need to populate the supersample buffer with all width*height*sample_rate samples. We do this in rasterize, then the user calls resolve_to_framebuffer and we downsize the supersize buffer by averaging each pixel's respective supersamples and that is what we color the respective pixel. Super sampling will smooth out jaggies and differences because we are taking many many more samples within each pixel. So if there happens to be a lot of detail in that one pixel if we take 16 super samples in the pixel we will reasonably be able to capture more detail of that complicated pixel.   </p>
  <div align="middle">
    <table style="width=100%">
      <tr>
        <td>
          <img src="./images/task2-1frame.png" align="middle" width="400px"/>
          <figcaption align="middle">We see with a sampling rate of 1 that we are completely missing some pixels apart of the very skinny triangle. .</figcaption>
        </td>
        <td>
          <img src="./images/task2-4frame.png" align="middle" width="400px"/>
          <figcaption align="middle">With a increased sampling rate of 4 we don't see any more gaps or completely missed pixels, we start to see the averaging out and blur that more correctly displays the shape of the triangle.</figcaption>
        </td>
        <td>
          <img src="./images/task2-16frame.png" align="middle" width="400px"/>
          <figcaption align="middle">With a sampling rate of 16 the skinny corner looks a lot better. We get a good shape and the color is right in that it gets more averaged as we explore the pixels with very small amounts of triangle in them..</figcaption>
        </td>
      </tr>
    </table>
  </div>



<h3 align="middle">Part 3: Transforms</h3>
  <img src="./images/my_robot.png" align="middle" width="400px"/>
  <figcaption align="middle">I have altered the robot to have black shoes and he's holding a basketball in his right hand and he is waving to his friend with his left hand. I was trying to make him look a bit more life like and to add some movement to his body. </figcaption>



<h2 align="middle">Section II: Sampling</h2>

<h3 align="middle">Part 4: Barycentric coordinates</h3>
  <div align="middle">
    <table style="width=100%">
      <tr>
        <td>
          <img src="./images/task4.png" align="right" width="400px"/>
          <figcaption align="left">Barycentric coordinates are used to smooth color changes out between pixels. If we specify values at the vertices of a triangle, then we can smoothly vary values across its surface. Images will look weird if there is no smoothing and the eye can pick up exactly where the color changes. Barycentric coordinates linearly interpolate the values at the indices, using very similar linear logic to the line tests for drawing the triangles. We are basically finding the distances to the three sides of the triangle and weighting their values by this distance to our point. This weighted average is our color for the pixel.  </figcaption>
        </td>
      </tr>
      <tr>
        <td>
          <img src="./images/task4test7.png" align="right" width="400px"/>
          <figcaption align="left">The circle has the correct gradient as well as the triangle I made. The triangle is colored green, blue, and red at its corners.</figcaption>
        </td>
      </tr>
    </table>
  </div>

<h3 align="middle">Part 5: "Pixel sampling" for texture mapping</h3>
  <p>Pixel sampling is how we antialias for texture in an image. We have a texture, and we need to put this into screenspace but this screenspace needs to reflect the world space. All this interpolation can cause moire or jaggies in certain parts of the image. We need to vary our sampling frequency in the screen space with respect to the texture space sampling. Some parts we should sample less and some more but this is all decided by the mapping function. Our task for this part was to implement the sampling for the texture locations. Nearest neighbor will sample from the nearest texel closest to the pixel center. In bilinear sampling we sample from the 4 closest texel neighbors and we again take a weighted average of these colors.  </p>
  <div align="middle">
    <table style="width=100%">
      <tr>
        <td>
          <img src="./images/nearest1f.png" align="middle" width="400px"/>
          <figcaption align="middle">With nearest neighbor the image is clear, but the texture of the globe is missing a little. It is also blocky in some areas.  </figcaption>
        </td>
        <td>
          <img src="./images/bilin16f.png" align="middle" width="400px"/>
          <figcaption align="middle">At 16 sampling rate and nearest neighbor sampling the blockiness goes away but the texture loses detail. Still looks pretty good.</figcaption>
        </td>
      </tr>
      <tr>
        <td>
          <img src="./images/task5bilin1.png" align="middle" width="400px"/>
          <figcaption align="middle">With bilinear sampling and at 1 sampling rate there is a little blocky looking but there is more texture detailed than with nearest neighbor.</figcaption>
        </td>
        <td>
          <img src="./images/task5bilin2f.png" align="middle" width="400px"/>
          <figcaption align="middle">With bilinear sampling and at 16 sampling rate we see a good detailed depiction of the coast line. Wee see where the water starts and the texture of the coastline.</figcaption>
        </td>
      </tr>
      </tr>
      <tr>
        <p>There will be a large difference between the two sampling methods when we magnify the images. Bilinear will remove the blockiness and a smooth gradient of color change will develop between texels. If we pull from the nearest neighbor in minification it works well but when we zoom in wee see clear changes in texture and it looks unnatural. Bilinear smooths the color change so the texture looks more natural, similar to how barycentric coordinates allowed us to create a smooth color gradient between pixels.</p>
      </tr>
    </table>
  </div>


<h3 align="middle">Part 6: "Level sampling" with mipmaps for texture mapping</h3>
  <p>Our goal is to depict and accurately describe textures in the world. The problem is that we may develop a textured polygon, but as we move it onto the screen space the entire texture might fall into a single pixel. We then need to filter the texture but this means reading all the texels and combining their values, this is way too much work and expensive. By using mipmaps and sampling relative to different mipmap levels we save costs. Mipmaps prefilter the texture and stores smaller sizes of the picture at worse resolutions. If a texture is going to be in the very background we can sample from a low resolution map. For this part of the project I call texture.sample() in rasterizer.rasrterize_textured_triangle() and from there I call the appropriate pixel sampling method with the user's level sampling method. The spec provided the computation for the nearest mipmap level. A difficult part was with billinear level sampling we had to compute the weighted average for two mipmap levels for a continuous level.  </p>

  <p>As we change the setting we get different results depending on the zoom and the texture we are looking at. For pixel sampling the bilinear is slower but the antialiasing is much better compared to nearest neighbor. For the level sampling the Level Zero is the slowest and the memory storage better than using many mip map levels. Storing all the different resolutions works out to adding around a 1/4 more of the original storage of the picture. With bilinear level sampling we got the best performance but lost texture in the zoom.</p>
  <div align="middle">
    <table style="width=100%">
      <tr>
        <td>
          <img src="./images/l_0andP_nearest.png" align="middle" width="400px"/>
          <figcaption align="middle">This image is with L_ZERO and P_NEAREST.</figcaption>
        </td>
        <td>
          <img src="./images/l0andplin.png" align="middle" width="400px"/>
          <figcaption align="middle">This image is with L_ZERO and P_LINEAR.</figcaption>
        </td>
      </tr>
      <tr>
        <td>
          <img src="./images/Lnearandpnear.png" align="middle" width="400px"/>
          <figcaption align="middle">This image is with L_NEAREST and P_NEAREST.</figcaption>
        </td>
        <td>
          <img src="./images/lnearandplin.png" align="middle" width="400px"/>
          <figcaption align="middle">This image is with L_NEAREST and P_LINEAR.</figcaption>
        </td>
      </tr>
    </table>
  </div>



</body>
</html>
